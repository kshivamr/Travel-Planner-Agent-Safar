{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://raw.githubusercontent.com/IBM/watson-machine-learning-samples/master/cloud/notebooks/headers/watsonx-Prompt_Lab-Notebook.png)\n",
    "# Agents Lab Notebook v1.0.0\n",
    "This notebook contains steps and code to demonstrate the use of agents\n",
    "configured in Agent Lab in watsonx.ai. It introduces Python API commands\n",
    "for authentication using API key and invoking a LangGraph agent with a watsonx chat model.\n",
    "\n",
    "**Note:** Notebook code generated using Agent Lab will execute successfully.\n",
    "If code is modified or reordered, there is no guarantee it will successfully execute.\n",
    "For details, see: <a href=\"/docs/content/wsj/analyze-data/fm-prompt-save.html?context=wx\" target=\"_blank\">Saving your work in Agent Lab as a notebook.</a>\n",
    "\n",
    "Some familiarity with Python is helpful. This notebook uses Python 3.11.\n",
    "\n",
    "## Notebook goals\n",
    "The learning goals of this notebook are:\n",
    "\n",
    "* Defining a Python function for obtaining credentials from the IBM Cloud personal API key\n",
    "* Creating an agent with a set of tools using a specified model and parameters\n",
    "* Invoking the agent to generate a response \n",
    "\n",
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHIVAM Notebook\n",
    "from langchain_ibm import ChatWatsonx\n",
    "from ibm_watsonx_ai import APIClient\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from ibm_watsonx_ai.foundation_models.utils import Tool, Toolkit\n",
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## watsonx API connection\n",
    "This cell defines the credentials required to work with watsonx API for Foundation\n",
    "Model inferencing.\n",
    "\n",
    "**Action:** Provide the IBM Cloud personal API key. For details, see\n",
    "<a href=\"https://cloud.ibm.com/docs/account?topic=account-userapikey&interface=ui\" target=\"_blank\">documentation</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "def get_credentials():\n",
    "\treturn {\n",
    "\t\t\"url\" : \"https://us-south.ml.cloud.ibm.com\",\n",
    "\t\t\"apikey\" : getpass.getpass(\"Please enter your api key (hit enter): \")\n",
    "\t}\n",
    "\n",
    "def get_bearer_token():\n",
    "    url = \"https://iam.cloud.ibm.com/identity/token\"\n",
    "    headers = {\"Content-Type\": \"application/x-www-form-urlencoded\"}\n",
    "    data = f\"grant_type=urn:ibm:params:oauth:grant-type:apikey&apikey={credentials['apikey']}\"\n",
    "\n",
    "    response = requests.post(url, headers=headers, data=data)\n",
    "    return response.json().get(\"access_token\")\n",
    "\n",
    "credentials = get_credentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the agent\n",
    "These cells demonstrate how to create and invoke the agent\n",
    "with the selected models, tools, and parameters.\n",
    "\n",
    "## Defining the model id\n",
    "We need to specify model id that will be used for inferencing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"ibm/granite-3-3-8b-instruct\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model parameters\n",
    "We need to provide a set of model parameters that will influence the\n",
    "result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    \"frequency_penalty\": 0,\n",
    "    \"max_tokens\": 2000,\n",
    "    \"presence_penalty\": 0,\n",
    "    \"temperature\": 0,\n",
    "    \"top_p\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the project id or space id\n",
    "The API requires project id or space id that provides the context for the call. We will obtain\n",
    "the id from the project or space in which this notebook runs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = os.getenv(\"PROJECT_ID\")\n",
    "space_id = os.getenv(\"SPACE_ID\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the agent\n",
    "We need to create the agent using the properties we defined so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = APIClient(credentials=credentials, project_id=project_id, space_id=space_id)\n",
    "\n",
    "# Create the chat model\n",
    "def create_chat_model():\n",
    "    chat_model = ChatWatsonx(\n",
    "        model_id=model_id,\n",
    "        url=credentials[\"url\"],\n",
    "        space_id=space_id,\n",
    "        project_id=project_id,\n",
    "        params=parameters,\n",
    "        watsonx_client=client,\n",
    "    )\n",
    "    return chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ibm_watsonx_ai.deployments import RuntimeContext\n",
    "\n",
    "context = RuntimeContext(api_client=client)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def create_utility_agent_tool(tool_name, params, api_client, **kwargs):\n",
    "    from langchain_core.tools import StructuredTool\n",
    "    utility_agent_tool = Toolkit(\n",
    "        api_client=api_client\n",
    "    ).get_tool(tool_name)\n",
    "\n",
    "    tool_description = utility_agent_tool.get(\"description\")\n",
    "\n",
    "    if (kwargs.get(\"tool_description\")):\n",
    "        tool_description = kwargs.get(\"tool_description\")\n",
    "    elif (utility_agent_tool.get(\"agent_description\")):\n",
    "        tool_description = utility_agent_tool.get(\"agent_description\")\n",
    "    \n",
    "    tool_schema = utility_agent_tool.get(\"input_schema\")\n",
    "    if (tool_schema == None):\n",
    "        tool_schema = {\n",
    "            \"type\": \"object\",\n",
    "            \"additionalProperties\": False,\n",
    "            \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "            \"properties\": {\n",
    "                \"input\": {\n",
    "                    \"description\": \"input for the tool\",\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def run_tool(**tool_input):\n",
    "        query = tool_input\n",
    "        if (utility_agent_tool.get(\"input_schema\") == None):\n",
    "            query = tool_input.get(\"input\")\n",
    "\n",
    "        results = utility_agent_tool.run(\n",
    "            input=query,\n",
    "            config=params\n",
    "        )\n",
    "        \n",
    "        return results.get(\"output\")\n",
    "    \n",
    "    return StructuredTool(\n",
    "        name=tool_name,\n",
    "        description = tool_description,\n",
    "        func=run_tool,\n",
    "        args_schema=tool_schema\n",
    "    )\n",
    "\n",
    "\n",
    "def create_custom_tool(tool_name, tool_description, tool_code, tool_schema, tool_params):\n",
    "    from langchain_core.tools import StructuredTool\n",
    "    import ast\n",
    "\n",
    "    def call_tool(**kwargs):\n",
    "        tree = ast.parse(tool_code, mode=\"exec\")\n",
    "        custom_tool_functions = [ x for x in tree.body if isinstance(x, ast.FunctionDef) ]\n",
    "        function_name = custom_tool_functions[0].name\n",
    "        compiled_code = compile(tree, 'custom_tool', 'exec')\n",
    "        namespace = tool_params if tool_params else {}\n",
    "        exec(compiled_code, namespace)\n",
    "        return namespace[function_name](**kwargs)\n",
    "        \n",
    "    tool = StructuredTool(\n",
    "        name=tool_name,\n",
    "        description = tool_description,\n",
    "        func=call_tool,\n",
    "        args_schema=tool_schema\n",
    "    )\n",
    "    return tool\n",
    "\n",
    "def create_custom_tools():\n",
    "    custom_tools = []\n",
    "\n",
    "\n",
    "def create_tools(context):\n",
    "    tools = []\n",
    "    \n",
    "    config = None\n",
    "    tools.append(create_utility_agent_tool(\"GoogleSearch\", config, client))\n",
    "    config = {\n",
    "    }\n",
    "    tools.append(create_utility_agent_tool(\"DuckDuckGo\", config, client))\n",
    "    config = {\n",
    "        \"maxResults\": 5\n",
    "    }\n",
    "    tools.append(create_utility_agent_tool(\"Wikipedia\", config, client))\n",
    "    config = {\n",
    "    }\n",
    "    tools.append(create_utility_agent_tool(\"Weather\", config, client))\n",
    "    config = {\n",
    "    }\n",
    "    tools.append(create_utility_agent_tool(\"WebCrawler\", config, client))\n",
    "\n",
    "    return tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_agent(context):\n",
    "    # Initialize the agent\n",
    "    chat_model = create_chat_model()\n",
    "    tools = create_tools(context)\n",
    "\n",
    "    memory = MemorySaver()\n",
    "    instructions = \"\"\"# Notes\n",
    "- Use markdown syntax for formatting code snippets, links, JSON, tables, images, files.\n",
    "- Any HTML tags must be wrapped in block quotes, for example ```<html>```.\n",
    "- When returning code blocks, specify language.\n",
    "- Sometimes, things don't go as planned. Tools may not provide useful information on the first few tries. You should always try a few different approaches before declaring the problem unsolvable.\n",
    "- When the tool doesn't give you what you were asking for, you must either use another tool or a different tool input.\n",
    "- When using search engines, you try different formulations of the query, possibly even in a different language.\n",
    "- You cannot do complex calculations, computations, or data manipulations without using tools.\n",
    "- If you need to call a tool to compute something, always call it instead of saying you will call it.\n",
    "\n",
    "If a tool returns an IMAGE in the result, you must include it in your answer as Markdown.\n",
    "\n",
    "Example:\n",
    "\n",
    "Tool result: IMAGE({commonApiUrl}/wx/v1-beta/utility_agent_tools/cache/images/plt-04e3c91ae04b47f8934a4e6b7d1fdc2c.png)\n",
    "Markdown to return to user: ![Generated image]({commonApiUrl}/wx/v1-beta/utility_agent_tools/cache/images/plt-04e3c91ae04b47f8934a4e6b7d1fdc2c.png)\n",
    "\n",
    "You are a helpful, friendly, and professional virtual assistant.\n",
    "\n",
    "Always follow these core instructions:\n",
    "\n",
    "1. Greet users politely and offer assistance clearly.\n",
    "2. Respond in a conversational, human-like tone.\n",
    "3. Keep your answers concise, relevant, and easy to understand.\n",
    "4. Ask for missing or unclear information when needed.\n",
    "5. Personalize responses based on the user‚Äôs inputs.\n",
    "6. Be polite and positive at all times, even if the user is frustrated.\n",
    "7. Do not provide false or fabricated information. If unsure, politely let the user know.\n",
    "8. Avoid technical jargon unless the user asks for it specifically.\n",
    "9. Do not share personal opinions. Stick to the assistant‚Äôs role.\n",
    "10. When asked something outside your scope, redirect the user politely or offer alternative help.\n",
    "11. Always provide clear next steps or helpful follow-up suggestions.\n",
    "12. Maintain user privacy and never ask for or store sensitive personal data unless explicitly required and permitted.\n",
    "\n",
    "Tone guidelines:\n",
    "- Use natural, friendly language.\n",
    "- Avoid overuse of emojis, unless the assistant has a casual persona.\n",
    "- Be clear and calm. Do not sound robotic or overly formal.\n",
    "\n",
    "\n",
    "You are a helpful assistant that uses tools to answer questions in detail.\n",
    "When greeted, say \\\"Hi, I am Travel Planner ai agent. How can I help you?\\\"\n",
    "\n",
    "You are a smart, friendly, and helpful Travel Planner Agent. Your job is to assist users in planning personalized travel experiences based on their input such as destination, travel dates, budget, and preferences.\n",
    "\n",
    "Always follow these rules:\n",
    "\n",
    "1. Greet the user warmly and offer help.\n",
    "2. Ask essential travel planning questions in a friendly, conversational tone:\n",
    "   - Destination\n",
    "   - Travel dates\n",
    "   - Budget\n",
    "   - Departure location\n",
    "   - Type of traveler (solo, couple, family, etc.)\n",
    "   - Preferred activities and interests\n",
    "   - Transport and accommodation preferences\n",
    "3. Suggest personalized destinations and itineraries based on user responses.\n",
    "4. Be concise, polite, and informative. Avoid long paragraphs.\n",
    "5. Respond naturally and clearly, as a human travel planner would.\n",
    "6. Use emojis occasionally to maintain a light and friendly tone (e.g., ‚úàÔ∏è, üèñÔ∏è, üåç), but only when appropriate.\n",
    "7. If the user input is unclear or incomplete, ask relevant follow-up questions to clarify.\n",
    "8. Summarize the final travel plan clearly, including:\n",
    "   - Suggested destination\n",
    "   - Itinerary (day-wise)\n",
    "   - Accommodation\n",
    "   - Transport mode\n",
    "   - Estimated cost\n",
    "   - Weather forecast (if applicable)\n",
    "9. Always offer next steps: ‚ÄúWould you like to save this plan?‚Äù, ‚ÄúDo you want hotel recommendations?‚Äù, etc.\n",
    "10. Maintain a positive tone. Avoid technical jargon unless asked.\n",
    "11. If you can't answer something, apologize and gently guide the user to what you *can* help with.\n",
    "\"\"\"\n",
    "\n",
    "    agent = create_react_agent(chat_model, tools=tools, checkpointer=memory, state_modifier=instructions)\n",
    "\n",
    "    return agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the graph\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
    "\n",
    "Image(\n",
    "    create_agent(context).get_graph().draw_mermaid_png(\n",
    "        draw_method=MermaidDrawMethod.API,\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking the agent\n",
    "Let us now use the created agent, pair it with the input, and generate the response to your question:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(context)\n",
    "\n",
    "def convert_messages(messages):\n",
    "    converted_messages = []\n",
    "    for message in messages:\n",
    "        if (message[\"role\"] == \"user\"):\n",
    "            converted_messages.append(HumanMessage(content=message[\"content\"]))\n",
    "        elif (message[\"role\"] == \"assistant\"):\n",
    "            converted_messages.append(AIMessage(content=message[\"content\"]))\n",
    "    return converted_messages\n",
    "\n",
    "question = input(\"Question: \")\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\",\n",
    "    \"content\": question\n",
    "}]\n",
    "\n",
    "generated_response = agent.invoke(\n",
    "    { \"messages\": convert_messages(messages) },\n",
    "    { \"configurable\": { \"thread_id\": \"42\" } }\n",
    ")\n",
    "\n",
    "print_full_response = False\n",
    "\n",
    "if (print_full_response):\n",
    "    print(generated_response)\n",
    "else:\n",
    "    result = generated_response[\"messages\"][-1].content\n",
    "    print(f\"Agent: {result}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
